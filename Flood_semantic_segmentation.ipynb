{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcESsomVEC4H"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIlMwoyZZft"
      },
      "source": [
        "**Mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvdaFSV9a4RR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUab8LnFZnbK"
      },
      "source": [
        "**Install and import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzkKpjyPtOxj"
      },
      "outputs": [],
      "source": [
        "pip install --quiet -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmo58UrnLzJd"
      },
      "outputs": [],
      "source": [
        "pip install --quiet torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqZq14Jmtj4L"
      },
      "outputs": [],
      "source": [
        "pip install --quiet segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nktLL_jaBjyJ"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLojFGHSt9yk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms.functional as tf\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torchvision.transforms import ToTensor\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations.augmentations.transforms import Normalize\n",
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import glob\n",
        "from torchmetrics.classification import MulticlassJaccardIndex, MulticlassF1Score, MulticlassAccuracy\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import pickle\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op-aPDpSZvEm"
      },
      "source": [
        "**Check GPU and setup device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBfJPVbeDM62"
      },
      "outputs": [],
      "source": [
        "# This function checks whether GPU is available. If yes, sets uo device = 'cuda:0' (GPU), otherwise device = 'cpu'\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Zc2ezPELgx"
      },
      "source": [
        "## Define useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvo8BGVHntn1"
      },
      "source": [
        "**Functions for data preprocessing** \\\\\n",
        "**1.** This function converts original 10 classes into 3 classes: background, building flooded, road flooded. Except the last two classes, everything becomes background. \\\\\n",
        "\n",
        "**2.** This function can be used in the Dataset class to retrieve the mask corresponding to the image by using the image number in the filepath."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAJ-PAPBnr5d"
      },
      "outputs": [],
      "source": [
        "# This function converts mask into three classes\n",
        "# Class 0 = background\n",
        "# Class 1 = building flooded\n",
        "# Class 2 = road flooded\n",
        "def three_classes(mask):\n",
        "  mask_3 = np.where((mask != 1)&(mask!= 3), 0, mask)\n",
        "  mask_3 = np.where(mask_3 == 3, 2, mask_3)\n",
        "  return mask_3\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "#This function reads only the image number from the filepath\n",
        "def get_img_number(path):\n",
        "  splits = path.split('/')\n",
        "  #keep only the last split and remove the '.jpg' chars\n",
        "  number = splits[-1][:-4]\n",
        "  return number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hiomodqknh33"
      },
      "source": [
        "**Functions for labeling** \\\\\n",
        "**1.** This function assigns a binary label to the image (0 = not flooded, 1 = flooded), based on whether more or less than 25% of the image is flooded. \\\\\n",
        "**2.** This function converts the binary label into string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiX13q3VVdUX"
      },
      "outputs": [],
      "source": [
        "# Assign a label to images based on how many pixels are flooded building or road\n",
        "# Label 1 = 'flooded' when percentage of flooded pixels is more or equal to 25% of the total pixels\n",
        "# Label 0 = 'non-flooded'\n",
        "\n",
        "def create_label(mask):\n",
        "  label = 0\n",
        "  tot_pixels = mask.flatten().shape[0]\n",
        "  flood_pixels = np.count_nonzero((mask != 0))\n",
        "  flood_perc = flood_pixels/tot_pixels\n",
        "  if flood_perc >= 0.25:\n",
        "    label = 1\n",
        "\n",
        "  return label\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#Use this function to convert binary label to 'flooded' when label = 1, or 'non flooded' when label = 0\n",
        "def bin_to_label(label):\n",
        "  if label == 0:\n",
        "    return 'non-flooded'\n",
        "  else:\n",
        "    return 'flooded'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOn-YyWsnpMb"
      },
      "source": [
        "**Functions for data inspection** \\\\\n",
        "This cell defines some useful variables for plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFrzZOqnBRNS"
      },
      "outputs": [],
      "source": [
        "# List of nominal classes (for plotting purposes)\n",
        "classes = ['background', 'building flooded', 'road flooded']\n",
        "\n",
        "#Define custom palette for classes plots\n",
        "palette = ['yellow', 'cyan','red']\n",
        "cmap_custom = mcolors.ListedColormap(palette)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvu6BY8bPdm"
      },
      "source": [
        "The following functions can be used to inspect the data: \\\\\n",
        "**1.** Creates a dictionary containing these information about the original dataset: n. of flooded and not flooded samples, sizes of all images and total pixel number, number of pixel per class for all images and corresponding percentage relative to total number of pixels, average percentage of background, flooded buildings and flooded roads in the dataset. \\\\\n",
        "\n",
        "**2.** Creates a barplot to compare label distribution in different datasets.\\\\\n",
        "\n",
        "**3.** Creates a histogram per class with the distribution of images per percentage of class pixels in the dataset.\\\\\n",
        "\n",
        "**4.** Makes an histogram based on the mask's pixel distribution per class. \\\\\n",
        "\n",
        "**5.** Plots one next to the other the original image, the mask with assigned label, the mask's histogram. \\\\\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEkyfWrUyCRe"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# 1. This functions defines a dictionary containing some statistics about the dataset\n",
        "def stats_original(dir):\n",
        "  ds_stats = dict()\n",
        "\n",
        "  mask_paths= glob.glob(f'{dir}/*label*/*')\n",
        "\n",
        "  #Variables to count how many flooded and non flooded images are present\n",
        "  ds_stats['non_flooded'] = 0\n",
        "  ds_stats['flooded'] = 0\n",
        "\n",
        "  #Array to store image sizes\n",
        "  ds_stats['img_size'] = np.zeros((len(mask_paths),2))\n",
        "  ds_stats['tot_pixels'] = np.zeros(len(mask_paths))\n",
        "\n",
        "  #Arrays to store pixel distribution per class\n",
        "  ds_stats['background'] = np.zeros(len(mask_paths))\n",
        "  ds_stats['building'] = np.zeros(len(mask_paths))\n",
        "  ds_stats['road'] = np.zeros(len(mask_paths))\n",
        "\n",
        "  for idx in range(len(mask_paths)):\n",
        "    mask = np.array(Image.open(mask_paths[idx]))\n",
        "    label = create_label(mask)\n",
        "\n",
        "    #Return image size\n",
        "    ds_stats['img_size'][idx] = mask.shape\n",
        "    ds_stats['tot_pixels'][idx] = ds_stats['img_size'][idx][0] * ds_stats['img_size'][idx][1]\n",
        "\n",
        "    #Cound flood or no flood\n",
        "    if label == 0:\n",
        "      ds_stats['non_flooded'] += 1\n",
        "    else:\n",
        "      ds_stats['flooded'] += 1\n",
        "\n",
        "    #Count how many pixels per class\n",
        "    ds_stats['background'][idx] = np.sum(np.where(mask == 0, 1, 0))\n",
        "    ds_stats['building'][idx] = np.sum(np.where(mask == 1, 1, 0))\n",
        "    ds_stats['road'][idx] = np.sum(np.where(mask == 2, 1, 0))\n",
        "\n",
        "  #Compute percentage of each class per image\n",
        "  ds_stats['perc_background']= ds_stats['background'] * 100 / ds_stats['tot_pixels']\n",
        "  ds_stats['perc_building'] = ds_stats['building'] * 100 / ds_stats['tot_pixels']\n",
        "  ds_stats['perc_road'] = ds_stats['road'] * 100 / ds_stats['tot_pixels']\n",
        "\n",
        "  #Compute average values\n",
        "  ds_stats['ave_background'] = np.mean(ds_stats['perc_background'])\n",
        "  ds_stats['ave_building'] = np.mean(ds_stats['perc_building'])\n",
        "  ds_stats['ave_road'] = np.mean(ds_stats['perc_road'])\n",
        "\n",
        "  return ds_stats\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 2. This function makes a barplot for the flooded, non-flooded distribution\n",
        "# flood_labels = list with number of flood labels for each dataset\n",
        "# noflood_labels = list with number of non-flood labels for each dataset\n",
        "def barplot(flood_labels, noflood_labels, dfs = ['Train', 'Validation', 'Test']):\n",
        "  r = np.arange(len(dfs))\n",
        "  width = 0.25\n",
        "\n",
        "  plt.bar(r, flood_labels, color = 'b',\n",
        "          width = width, edgecolor = 'black',\n",
        "          label='Flooded')\n",
        "  plt.bar(r + width, noflood_labels, color = 'pink',\n",
        "          width = width, edgecolor = 'black',\n",
        "          label='Not flooded')\n",
        "\n",
        "  plt.xlabel(\"Dataset\", fontsize = 12)\n",
        "  plt.ylabel(\"Number of images\")\n",
        "  plt.title(\"Number of flooded and not flooded images per dataset\")\n",
        "\n",
        "  plt.xticks(r + width/2, dfs)\n",
        "  plt.legend()\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 3. Make three histograms for different classes\n",
        "def class_hist(dict, df_name):\n",
        "  plt.subplots(1,3, figsize = (15,5))\n",
        "\n",
        "  #First histogram for percentage of background\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.hist(dict['perc_background'], bins = 10, range = (-5,105))\n",
        "  plt.title(f'% Background in {df_name} set')\n",
        "  plt.xlabel('%')\n",
        "  plt.ylabel('Occurrences')\n",
        "  plt.xlim(-5,105)\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  #Second histogram for percentage of flooded buildings\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.hist(dict['perc_building'], bins = 10, range = (-5,105))\n",
        "  plt.title(f'% Flooded buildings in {df_name} set')\n",
        "  plt.xlabel('%')\n",
        "  plt.ylabel('Occurrences')\n",
        "  plt.xlim(-5,105)\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  #Third histogram for percentage of flooded roads\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.hist(dict['perc_road'], bins = 10, range = (-5,105))\n",
        "  plt.title(f'% Flooded roads in {df_name} set')\n",
        "  plt.xlabel('%')\n",
        "  plt.ylabel('Occurrences')\n",
        "  plt.xlim(-5,105)\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 4. This function shows the distribution of each class in the mask with a histogram\n",
        "def mask_hist(mask):\n",
        "  hist = plt.hist(mask.flatten(), bins = 3, range = (-0.5, 2.5))\n",
        "  ticks = np.arange(0,3,1)\n",
        "  plt.xticks(ticks, labels = classes, rotation = 90)\n",
        "  plt.xlabel('Class')\n",
        "  plt.ylabel('N. of pixels')\n",
        "  plt.title('Pixel distribution per class')\n",
        "  plt.grid(alpha = 0.5)\n",
        "  plt.show()\n",
        "  return hist\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 2. This function plots the image, the mask with corresponding label, and the histogram of the mask\n",
        "def plot_item(img, mask, label):\n",
        "  max_img = img.max()\n",
        "  min_img = img.min()\n",
        "\n",
        "  max_msk = mask.max()\n",
        "  min_msk = mask.min()\n",
        "\n",
        "  plt.subplots(1,3,figsize =(20,5))\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.title('Original image')\n",
        "  plt.imshow(img, vmin = min_img, vmax = max_img)\n",
        "  #plt.imshow(img.permute(1,2,0), vmin = min_img, vmax = max_img)\n",
        "\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.imshow(mask, vmin = min_msk, vmax = max_msk, cmap = cmap_custom)\n",
        "  plt.title(f'Mask: {bin_to_label(label)}')\n",
        "  plt.colorbar(orientation = 'vertical', ticks = range(0,3))\n",
        "  plt.clim(-0.5,2.5)\n",
        "\n",
        "  plt.subplot(1,3,3)\n",
        "  hist = mask_hist(mask)\n",
        "\n",
        "  plt.show()\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aykT0P8egTmL"
      },
      "source": [
        "**Functions for the models** \\\\\n",
        "This function takes as input the output of the model and applies a softmax2d activation function to convert the output to probabilities. For each pixel, the segmentation mask contains the index of the layer with highest probability (which also corresponds to class 0, 1, or 2). The function returns the mask, moved the cpu, as a numpy array and as a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbzQ3QAwggd9"
      },
      "outputs": [],
      "source": [
        "# This function transforms into one channel the output of the model by taking the maximum value per pixel among all channels\n",
        "def output_to_mask(output):\n",
        "  output = output.squeeze(0)\n",
        "  softmax = nn.Softmax2d()\n",
        "  output = softmax(output)\n",
        "  segm = np.argmax(output.cpu().detach().numpy(), axis = 0, keepdims = True)\n",
        "  segm = segm.squeeze(0)\n",
        "  segm_tensor = torch.tensor(segm).to(device)\n",
        "  return segm, segm_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk8vu2EN-oyo"
      },
      "source": [
        "# Prepare dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2W71SQJbG5J"
      },
      "outputs": [],
      "source": [
        "# Define data directories\n",
        "train_dir = 'Flood_data/train_new'\n",
        "val_dir = 'Flood_data/val'\n",
        "test_dir = 'Flood_data/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNkv7pOuzqxd"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define transformations** \\\\\n",
        "Different transformations are defined for train set and validation and testing sets, since training set may include data augmentation.\n",
        "Normalization is defined separately because it is only applied to the image and not to the mask."
      ],
      "metadata": {
        "id": "D4lCewE9wP0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSO_CO2__okA"
      },
      "outputs": [],
      "source": [
        "#--Train set transformations--\n",
        "# Images have a 50% probability of being cropped to a slightly smaller image size (zoom in)\n",
        "# Resized to 256x256 pixels and converted to tensors\n",
        "train_transform = A.Compose([\n",
        "                            A.RandomCrop(width= 3600, height= 2700, p = 0.5),   #crop by 0.9 factor to slightly zoom in\n",
        "                            A.Resize(256, 256),\n",
        "                            ToTensorV2()\n",
        "                            ],is_check_shapes=False)\n",
        "\n",
        "\n",
        "#--Test and validation transformations--\n",
        "# Resized to 256x256 pixels and converted to tensors\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(256, 256),\n",
        "                            ToTensorV2()\n",
        "                            ],is_check_shapes=False)\n",
        "\n",
        "#--Normalize--\n",
        "# Data is normalized for the pretrained model\n",
        "normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en4Us6-6YDiH"
      },
      "source": [
        "**Dataset class** \\\\\n",
        "* This class function receives as root directory of images and labels, possible transformations and whether the class is used for validation sets (includes also test set).\n",
        "* When val = True, the mask is converted into three classes. Augmented training masks already contain three classes. \\\\\n",
        "* It contains a function which returns the length of the dataset and a function which returns the image, mask and label at a certain index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUv3OzS839FJ"
      },
      "outputs": [],
      "source": [
        "#--Define dataset class--\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  # Initialize dataset class, default transforms = None, default val = False\n",
        "  def __init__(self, root_dir, transforms = None, val = False):\n",
        "        #Save all image paths and transforms\n",
        "        self.root_dir = root_dir\n",
        "        self.img_paths= glob.glob(f'{self.root_dir}/*org*/*')\n",
        "        self.transform = transforms\n",
        "        self.val = val\n",
        "\n",
        "  def __len__(self):\n",
        "      # here i will return the number of samples in the dataset\n",
        "      return len(self.img_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      #Open image at index idx following folder paths\n",
        "      img = np.array(Image.open(f'{self.img_paths[idx]}'))\n",
        "      #Get the image number from image path to find the corresponding mask\n",
        "      img_number = get_img_number(self.img_paths[idx])\n",
        "\n",
        "      #Define mask path\n",
        "      mask_path = glob.glob(f'{self.root_dir}/*label*/{img_number}*')[0]        #glob.glob returns a list so we only want the first element\n",
        "      #Open corresponding mask\n",
        "      mask = np.array(Image.open(f'{mask_path}'))\n",
        "\n",
        "      #Convert to three classes if validation or test set is used\n",
        "      if self.val:\n",
        "        mask = three_classes(mask)\n",
        "\n",
        "      #If any transformation is passed to the Dataset, apply transformations on image and mask\n",
        "      if self.transform != None:\n",
        "        #First normalize the image (not the mask)\n",
        "        img = normalize(image = img)['image']\n",
        "        #Apply transformations\n",
        "        transf = self.transform(image = img, mask = mask)\n",
        "        img = transf['image']\n",
        "        mask = transf['mask']\n",
        "\n",
        "      #Create the label of the original or the transformed mask\n",
        "      label = create_label(mask)\n",
        "\n",
        "      return img, mask, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHK5anZzoBr"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ’€ **Dangerous function: do not set to 'True'** ðŸ’€ \\\\\n",
        "\n",
        "* When ext_augment = True, this function will create a new training set with\n",
        "augmented images.\n",
        "* Seven augmentations are applied to images with label 1 (flooded) to balance the dataset in terms of flooded and not flooded images. The first transformations are geometric and are applied to both image and mask; the second set of transformations are color-related so they should be applied only to images. \\\\\n",
        "* In this function, all training data is saved to a new folder, but only flooded images are augmented. \\\\\n",
        "\n",
        "ðŸ•“ Estimated running time is one hour."
      ],
      "metadata": {
        "id": "pA9jzr2oVCBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy98V6BJybUf"
      },
      "outputs": [],
      "source": [
        "ext_augment = False\n",
        "\n",
        "if ext_augment:\n",
        "  n = 1\n",
        "  transforms_all = A.Compose([\n",
        "                          A.HorizontalFlip(p=1),\n",
        "                          A.Compose([A.HorizontalFlip(p=1),A.VerticalFlip(p=1)]),\n",
        "                          A.VerticalFlip(p=1)])\n",
        "\n",
        "  transforms_img = A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.5, p =1),\n",
        "                              A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=20, val_shift_limit = 10, p =1),\n",
        "                              A.GaussianBlur(blur_limit = (9,19), p =1),\n",
        "                              A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.5, p =1),\n",
        "                                         A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=20, val_shift_limit = 10, p =1),\n",
        "                                         A.GaussianBlur(blur_limit = (9,19), p =1)])])\n",
        "\n",
        "  #Source directory where training images to be augmented are found\n",
        "  source_train_dir = 'Flood_data_old/train'\n",
        "  to_augment = Dataset(source_train_dir)\n",
        "\n",
        "  #progress bar\n",
        "  tqdm_images = tqdm_notebook(total = to_augment.__len__(), desc ='Image')\n",
        "\n",
        "  for idx in range(0, len(to_augment)+1):\n",
        "\n",
        "    image, mask, label = to_augment[idx]\n",
        "\n",
        "    img_number = get_img_number(to_augment.img_paths[idx])\n",
        "    # Save original image and mask with original number\n",
        "    (Image.fromarray(image)).save(f'{train_dir}_new/train-org-img/{img_number}.jpg')\n",
        "    (Image.fromarray(mask)).save(f'{train_dir}_new/train-label-img/{img_number}_lab.png')\n",
        "\n",
        "    # When images are assigned to label = 'flooded' they are saved with img_number = n (dynamic)\n",
        "    if label == 1:\n",
        "\n",
        "      #Apply geometric transformations\n",
        "      for transf in transforms_all:\n",
        "        t = transf(image = image, mask = mask)\n",
        "        img = tf.to_pil_image(t['image'])\n",
        "        msk = tf.to_pil_image(t['mask'])\n",
        "        img.save(f'{train_dir}_new/train-org-img/{n}.jpg')\n",
        "        msk.save(f'{train_dir}_new/train-label-img/{n}_lab.png')\n",
        "        n += 1\n",
        "\n",
        "      n = n\n",
        "      #Apply color transformations\n",
        "      for transf in transforms_img:\n",
        "        t = transf(image = image)\n",
        "        img = tf.to_pil_image(t['image'])\n",
        "        msk = tf.to_pil_image(mask)\n",
        "        img.save(f'{train_dir}_new/train-org-img/{n}.jpg')\n",
        "        msk.save(f'{train_dir}_new/train-label-img/{n}_lab.png')\n",
        "        n += 1\n",
        "\n",
        "    tqdm_images.update(1)\n",
        "\n",
        "  tqdm_images.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GD7PhwVfXT2"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gCbn86UVJPQ"
      },
      "outputs": [],
      "source": [
        "#Import training, testing and validation datasets to be used for training the model (apply transformations)\n",
        "trainset = Dataset(train_dir, transforms = train_transform)\n",
        "valset = Dataset(val_dir, transforms = test_transform, val = True)\n",
        "testset = Dataset(test_dir, transforms = test_transform, val = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf4D6pUpYtE2"
      },
      "outputs": [],
      "source": [
        "#--Create dataloaders--\n",
        "batch_size = 40\n",
        "\n",
        "trainloader = DataLoader(trainset,\n",
        "                         batch_size = batch_size,\n",
        "                         shuffle = True,\n",
        "                         drop_last = True,\n",
        "                         num_workers = 0)\n",
        "testloader = DataLoader(testset,\n",
        "                        batch_size = 1,\n",
        "                        shuffle = False,\n",
        "                        drop_last = False,\n",
        "                        num_workers = 0)\n",
        "valloader = DataLoader(valset,\n",
        "                        batch_size = 1,\n",
        "                        shuffle = False,\n",
        "                        drop_last = False,\n",
        "                        num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ-Mqo_3Nsni"
      },
      "source": [
        "# Explore data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize sample image**"
      ],
      "metadata": {
        "id": "SGtwRF4LhBaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for img, mask,label in Dataset(train_dir):\n",
        "  plot_item(img, mask, label)\n",
        "\n",
        "  if i == 10:\n",
        "    break"
      ],
      "metadata": {
        "id": "oYaWnVZXhDpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for img, mask,label in testset:\n",
        "  plot_item(img, mask, label)\n",
        "\n",
        "  if i == 2:\n",
        "    break"
      ],
      "metadata": {
        "id": "xozndHVXW8Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute dataset statistics** \\\\\n",
        "* This cell computes a dictionary with statistics of each dataset or loads it if already computed.\n",
        "* It is possible to compute the dictionary, save it and load it.\n",
        "* Contents of the dictionary are described in section 'Define useful functions'\n"
      ],
      "metadata": {
        "id": "MTYHvVZB2poH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgmLHuMvS6x7"
      },
      "outputs": [],
      "source": [
        "compute_stats = False\n",
        "save = False\n",
        "load = True\n",
        "\n",
        "if compute_stats:\n",
        "  dict_val = stats_original(val_dir)\n",
        "  dict_test = stats_original(test_dir)\n",
        "  dict_train = stats_original(train_dir)\n",
        "\n",
        "  if save:\n",
        "    with open('/content/drive/MyDrive/ACT/Final project/Useful_items/val_dict.pkl', 'wb') as f:\n",
        "      pickle.dump(dict_val, f)\n",
        "    f.close()\n",
        "\n",
        "    with open('/content/drive/MyDrive/ACT/Final project/Useful_items/test_dict.pkl', 'wb') as f:\n",
        "      pickle.dump(dict_test, f)\n",
        "    f.close()\n",
        "\n",
        "    with open('/content/drive/MyDrive/ACT/Final project/Useful_items/train_dict.pkl', 'wb') as f:\n",
        "      pickle.dump(dict_train, f)\n",
        "    f.close()\n",
        "\n",
        "if load:\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Useful_items/val_dict.pkl', 'rb') as f:\n",
        "    dict_val = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Useful_items/test_dict.pkl', 'rb') as f:\n",
        "    dict_test = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Useful_items/train_dict.pkl', 'rb') as f:\n",
        "    dict_train = pickle.load(f)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Label distribution** \\\\\n",
        "The following plot shows the distribution of labels in each dataset."
      ],
      "metadata": {
        "id": "J_Xd_Kx03Pkb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn61FgDQcakn"
      },
      "outputs": [],
      "source": [
        "# Store number of labels per dataset as two lists to pass to the barplot function\n",
        "flooded = [dict_train['flooded'], dict_val['flooded'], dict_test['flooded']]\n",
        "notflooded = [dict_train['non_flooded'], dict_val['non_flooded'], dict_test['non_flooded']]\n",
        "\n",
        "# Barplot function takes in list of number of flooded and non-flooded labels per dataset and the names of datasets for plotting\n",
        "barplot(flooded, notflooded, ['Train', 'Validation', 'Test'])\n",
        "\n",
        "print('Number of flooded images in train set: ', flooded[0])\n",
        "print('Number of not flooded images in train set: ', notflooded[0])\n",
        "\n",
        "print('Number of flooded images in validation set: ', flooded[1])\n",
        "print('Number of not flooded images in validation set: ', notflooded[1])\n",
        "\n",
        "print('Number of flooded images in test set: ', flooded[2])\n",
        "print('Number of not flooded images in test set: ', notflooded[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image distribution per percentage of class pixels** \\\\\n",
        "These plots show the distribution of images in each dataset as a function of percentage of pixels for each class: 1) background, 2) flooded buildings, 3) flooded roads."
      ],
      "metadata": {
        "id": "-I70so7H5Y8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWDP_Tmckn1d"
      },
      "outputs": [],
      "source": [
        "class_hist(dict_train, 'training')\n",
        "class_hist(dict_val, 'validation')\n",
        "class_hist(dict_test, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEq7pw6nlajs"
      },
      "source": [
        "# UNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define UNet model** \\\\\n",
        "This function defines the segmentation model by using the smp library where:\n",
        "* encoder is pretrained EfficientNet B2\n",
        "* encoder used pretrained weights on ImageNet\n",
        "* output classes of the net is 3"
      ],
      "metadata": {
        "id": "tXF_TNUv5zf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE0B9Plrlby1"
      },
      "outputs": [],
      "source": [
        "model = smp.Unet(\n",
        "        encoder_name = \"efficientnet-b2\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "        encoder_weights = \"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "        encoder_depth = 5,\n",
        "        in_channels = 3,                  # model input channels (1 for gray-scale images, 3 for RGB)\n",
        "        classes = 3,                     # model output channels (number of classes in your dataset)\n",
        "        activation = 'sigmoid'\n",
        "        )\n",
        "\n",
        "\n",
        "# Net is moved to device (can be cpu or gpu/cuda)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBBqbo7nlhd5"
      },
      "source": [
        "# Train and evaluate model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload model if already trained** \\\\\n",
        "This cell allows to:\n",
        "1. Import an already trained version of the model.\n",
        "2. **Transfer learning**: freeze layers of the encoder to update only the decoder weights during training."
      ],
      "metadata": {
        "id": "diqTxB3DsnnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOCYebMwmyZa"
      },
      "outputs": [],
      "source": [
        "# To import the previous best model and continue training, set 'load_model' to True\n",
        "load_model = True\n",
        "\n",
        "if load_model:\n",
        "  checkpoint = torch.load(\"Models/FloodSegmentation3_dataaugm_best.pth\", map_location = device)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  model.to(device)\n",
        "\n",
        "#---------------------------------------------------------------------------------\n",
        "freeze_layers = True\n",
        "\n",
        "if freeze_layers:\n",
        "  ## Iteration to freeze first layers and only train the last ones\n",
        "  for key, value in dict(model.named_children()).items():\n",
        "    if \"encoder\" in key:\n",
        "      for param in value.parameters():\n",
        "          param.requires_grad = False\n",
        "    else:\n",
        "      for param in value.parameters():\n",
        "          param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define function to validate the model** \\\\\n",
        "This function is used to validate the model by computing IoU score and Dice score for segmentation image, and micro and macro accuracy for predicted label.\n",
        "The predicted label is computed based on the number of flooded pixels in the image. \\\\\n",
        "\n",
        "* When return_labels = True, ground truth and predicted labels are returned (use for testing).\n",
        "\n",
        "* **N.B.** The dataloader passed to this function must have batch_size = 1."
      ],
      "metadata": {
        "id": "6J42b5Bvssre"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRhCLi0VH4wO"
      },
      "outputs": [],
      "source": [
        "# Create validation routine\n",
        "\n",
        "def validate(net, valloader, device, return_labels = False):\n",
        "\n",
        "    # Get final scores for IoU, Dice, micro and macro accuracy\n",
        "    iou_score = MulticlassJaccardIndex(num_classes=3, average = 'macro')\n",
        "    dice_score = MulticlassF1Score(num_classes=3, average = 'macro')\n",
        "    accuracy_micro = Accuracy(task = 'multiclass', num_classes = 3, average = 'micro')\n",
        "    accuracy_macro = Accuracy(task = 'multiclass', num_classes = 3, average = 'macro')\n",
        "\n",
        "    # Move metrics to device\n",
        "    iou_score = iou_score.to(device)\n",
        "    dice_score = dice_score.to(device)\n",
        "    accuracy_micro = accuracy_micro.to(device)\n",
        "    accuracy_macro = accuracy_macro.to(device)\n",
        "\n",
        "    # Set network in eval mode\n",
        "    net.eval()\n",
        "\n",
        "    #Lists to store ground truth labels and predicted labels\n",
        "    gt_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    n=0\n",
        "\n",
        "    tqdm_val = tqdm_notebook(total= valset.__len__(), desc='Validation progress', unit='Image')\n",
        "\n",
        "    # At the end of epoch, validate model\n",
        "    for inp, mask, label in valloader:\n",
        "\n",
        "        # Move batch to gpu\n",
        "        inp = inp.to(device)\n",
        "        mask = mask.to(device)\n",
        "        label = label\n",
        "\n",
        "        # Get output mask\n",
        "        with torch.no_grad():\n",
        "            outmask = net(inp)\n",
        "\n",
        "        # Create a segmentation mask as numpy array and one as tensor\n",
        "        segm_mask, segm_mask_tensor = output_to_mask(outmask)\n",
        "\n",
        "        # Create first label to add to pred_labels from segmentation mask\n",
        "        # Second label is formatted as a torch element of the batch\n",
        "        segm_label = create_label(segm_mask)\n",
        "        segm_label_tensor = torch.tensor(segm_label).unsqueeze(0).to(device)\n",
        "\n",
        "        # Add ground truth label (taken from tensor) and segmentation result to lists\n",
        "        gt_labels += [label.item()]\n",
        "        pred_labels += [segm_label]\n",
        "\n",
        "        # Update metrics for each item\n",
        "        iou_score.update(segm_mask_tensor, mask.squeeze(0))\n",
        "        dice_score.update(segm_mask_tensor, mask.squeeze(0))\n",
        "        accuracy_micro.update(segm_label_tensor, label.to(device))\n",
        "        accuracy_macro.update(segm_label_tensor, label.to(device))\n",
        "\n",
        "        tqdm_val.update(1)\n",
        "        n += 1\n",
        "\n",
        "    # Compute metrics for segmentation tensor vs. original mask\n",
        "    iou_score = iou_score.compute()\n",
        "    dice_score = dice_score.compute()\n",
        "    accuracy_micro = accuracy_micro.compute()\n",
        "    accuracy_macro = accuracy_macro.compute()\n",
        "    print(iou_score, dice_score, accuracy_micro, accuracy_macro)\n",
        "\n",
        "    # set network in training mode\n",
        "    net.train()\n",
        "\n",
        "    if return_labels:\n",
        "      return iou_score, dice_score, accuracy_micro, accuracy_macro, gt_labels, pred_labels\n",
        "\n",
        "    else:\n",
        "      return iou_score, dice_score, accuracy_micro, accuracy_macro"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "UXCSKRFSswqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup tensorboard**\n",
        "* Define name of the experiment to store model training.\n",
        "* Launch tensorboard"
      ],
      "metadata": {
        "id": "6xKG2bMltAwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbB4AZ63lj2P"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'FloodSegmentation3_dataaugm'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBV1k4iJHz-Z"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "#%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir={experiment_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Launch training** \\\\\n",
        "* When train = True, this cells trains the network. \\\\\n",
        "* The loss function used for training the Cross Entropy Loss. The model is trained and optimized only based on the segmentation prediction (**not on label**). \\\\\n",
        "* Validation is run at the end of each epoch and the model with best IoU and Dice score is saved as best model.\n"
      ],
      "metadata": {
        "id": "dZM4ILBwtDaV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIHmSLBPQ_Qt"
      },
      "outputs": [],
      "source": [
        "train = False\n",
        "\n",
        "if train:\n",
        "\n",
        "  cross_entropy = nn.CrossEntropyLoss()\n",
        "  model = model.to(device)\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  # define Adam optimizer\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr= learning_rate)\n",
        "\n",
        "  # define summary writer\n",
        "  writer = SummaryWriter(experiment_name)\n",
        "\n",
        "  # initialize iteration number\n",
        "  n_iter = 0\n",
        "\n",
        "  # define best validation value\n",
        "  best_val_dice = 0\n",
        "  best_val_iou = 0\n",
        "\n",
        "  # number of epoch\n",
        "  n_epoch = 10\n",
        "  total_batches = len(trainset)//batch_size\n",
        "\n",
        "  #Progress bar for epochs\n",
        "  tqdm_epochs = tqdm_notebook(total=n_epoch, desc='Epochs')\n",
        "\n",
        "  for cur_epoch in range(n_epoch):\n",
        "      # plot current epoch\n",
        "      writer.add_scalar(\"epoch\", cur_epoch, n_iter)\n",
        "\n",
        "      # Progress bar for batches\n",
        "      tqdm_batches = tqdm_notebook(total= total_batches, desc=f'Epoch {cur_epoch}')\n",
        "\n",
        "      for inp, mask, label in trainloader:\n",
        "          # move batch to gpu\n",
        "          inp = inp.to(device)\n",
        "          mask = mask.to(device)\n",
        "\n",
        "          # reset gradients\n",
        "          optimizer.zero_grad()\n",
        "          # get output\n",
        "          outmask = model(inp)\n",
        "\n",
        "          # compute loss\n",
        "          loss = nn.CrossEntropyLoss().to(device)\n",
        "          loss = loss(outmask, mask.long())\n",
        "          loss.backward()\n",
        "\n",
        "          # update weights\n",
        "          optimizer.step()\n",
        "\n",
        "          #Plot\n",
        "          writer.add_scalar(\"Loss\",loss.item(), n_iter)\n",
        "\n",
        "          #Update progress bar\n",
        "          tqdm_batches.update(1)\n",
        "          n_iter += 1\n",
        "\n",
        "      # At the end, validate model\n",
        "      # Validate the model with IoU, Dice, micro and macro accuracy\n",
        "      cur_iou, cur_dice, cur_accuracy_micro, cur_accuracy_macro = validate(model, valloader, device)\n",
        "\n",
        "      # plot validation scores\n",
        "      writer.add_scalar(\"Dice\", cur_dice, cur_epoch)\n",
        "      writer.add_scalar(\"IoU\", cur_iou, cur_epoch)\n",
        "      writer.add_scalar(\"Micro Accuracy\", cur_accuracy_micro, cur_epoch)\n",
        "      writer.add_scalar(\"Macro Accuracy\", cur_accuracy_macro, cur_epoch)\n",
        "\n",
        "      # Check if it is the best model so far\n",
        "      if (best_val_dice is None or cur_dice >= best_val_dice) and (best_val_iou is None or cur_iou >= best_val_iou):\n",
        "          # define new best val\n",
        "          best_val_dice = cur_dice\n",
        "          best_val_iou = cur_iou\n",
        "\n",
        "          # save current model as best\n",
        "          torch.save({\n",
        "              'model': model.state_dict(),\n",
        "              'opt': optimizer.state_dict(),\n",
        "              'epoch': cur_epoch\n",
        "          }, 'Models/' + experiment_name + '_best.pth')\n",
        "\n",
        "      # save last model\n",
        "      torch.save({\n",
        "          'model': model.state_dict(),\n",
        "          'opt': optimizer.state_dict(),\n",
        "          'epoch': cur_epoch\n",
        "      }, 'Models/' + experiment_name + '_last.pth')\n",
        "\n",
        "      tqdm_batches.close()\n",
        "      tqdm_epochs.update(1)\n",
        "\n",
        "  tqdm_epochs.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FEnLY6VlkNK"
      },
      "source": [
        "# Test model on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute metrics for test set** \\\\\n",
        "The validation function is also used to validate the model with the test set. return_labels = True to compute confusion matrix."
      ],
      "metadata": {
        "id": "qL2l_E6h-LKE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYnTzH1jllrG"
      },
      "outputs": [],
      "source": [
        "# Get metrics and labels for test set\n",
        "iou, dice, acc_micro, acc_macro, gt_labels, pred_labels = validate(model, testloader, device, return_labels= True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot confusion matrix using predicted and true labels\n",
        "cm = confusion_matrix(gt_labels, pred_labels)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n",
        "                              display_labels= [0,1])\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RfHr6g5SsZg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize test results** \\\\\n",
        "This cell iterates over the test loader and computed segmented mask and label. It also prints the following:\n",
        "* Plot of the original image, original mask and label\n",
        "* Plot of the original image, segmented mask and predicted label\n",
        "\\\\\n",
        "\n",
        "**N.B.** The function breaks at i == 30."
      ],
      "metadata": {
        "id": "YaGxoY1J-yZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for img, msk, lab in testloader:\n",
        "  model.eval()\n",
        "  outmask = model(img)\n",
        "  segm_mask, _ = output_to_mask(outmask)\n",
        "\n",
        "  plot_item(img.squeeze(0).cpu(), msk.squeeze(0).cpu(), create_label(msk))\n",
        "  plt.show()\n",
        "\n",
        "  plot_item(img.squeeze(0).cpu(), segm_mask, create_label(segm_mask))\n",
        "  plt.show()\n",
        "\n",
        "  i += 1\n",
        "\n",
        "  if i == 30:\n",
        "    break"
      ],
      "metadata": {
        "id": "i4OBSD7u8C6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNImOe2AWHqV"
      },
      "source": [
        "# Encoded features extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Place a hook at the end of the encoder**"
      ],
      "metadata": {
        "id": "uhIUXXGQ_cyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfnsFBlhEy_T"
      },
      "outputs": [],
      "source": [
        "# This function registers a forward hook on a specified module of the model\n",
        "class Hook():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.input = input\n",
        "        self.output = output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAMNvvL8m9oJ"
      },
      "outputs": [],
      "source": [
        "# Use this function to load the model for feature extraction\n",
        "load_model = True\n",
        "if load_model:\n",
        "  #Load model\n",
        "  checkpoint = torch.load(\"Models/FloodSegmentation3_dataaugm_best.pth\", map_location = device)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  model.to(device)\n",
        "\n",
        "# Register a hook on the last layer of the encoder\n",
        "model.hook = Hook(model.encoder._blocks[21])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test feature extraction** \\\\\n",
        "**N.B.** It is necessary to run this cell to define 'features_shape'."
      ],
      "metadata": {
        "id": "m8jUE2aG_1w4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOQJDYaIziZK"
      },
      "outputs": [],
      "source": [
        "# Try to extract features from a sample image\n",
        "outmask = model(trainset.__getitem__(100)[0].to(device).unsqueeze(0))\n",
        "features = model.hook.output\n",
        "features_shape = np.array(features.squeeze(0).shape)\n",
        "flat_output_size = features.flatten().shape[0]\n",
        "print(np.array(features_shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teYJRN2kWNos"
      },
      "source": [
        "**Load features** \\\\\n",
        "If load_features = True, extracted features and corresponding labels are imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0qMm-Qe0Pie"
      },
      "outputs": [],
      "source": [
        "load_features = True\n",
        "\n",
        "if load_features:\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/train_labels.pkl', 'rb') as f:\n",
        "    train_labels = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/train_features.pkl', 'rb') as f:\n",
        "    train_features = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/test_labels.pkl', 'rb') as f:\n",
        "    test_labels = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/test_features.pkl', 'rb') as f:\n",
        "    test_features = pickle.load(f)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute features** \\\\\n",
        "The following cells can be run to extract features at the end of the decoder for train set and test set. Corresponding ground truth labels are also saved. When features and labels are extracted, they are automatically saved externally."
      ],
      "metadata": {
        "id": "erQuBV-gAbp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6ZHqu-rWiH5"
      },
      "outputs": [],
      "source": [
        "if load_features == False:\n",
        "  # Create an empty array to allocate all trainset labels\n",
        "  # Create an empty array to allocate all trainset features\n",
        "  train_labels = np.zeros((trainset.__len__()//batch_size, batch_size))\n",
        "  train_features = np.zeros((trainset.__len__()//batch_size, batch_size, features_shape[0], features_shape[1], features_shape[2]))\n",
        "\n",
        "  n = 0\n",
        "\n",
        "  tqdm_batches = tqdm_notebook(total= trainset.__len__()//batch_size, desc=f'Training set', unit='batch')\n",
        "\n",
        "  for inp, mask, label in trainloader:\n",
        "    inp = inp.to(device)\n",
        "    mask = mask.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Allocate label\n",
        "    train_labels[n] = label.cpu().numpy()\n",
        "\n",
        "    # Run the model with input image and extract features where hook is placed\n",
        "    with torch.no_grad():\n",
        "      outmask = model(inp)\n",
        "      train_features[n] = (model.hook.output).cpu().numpy()\n",
        "\n",
        "    n += 1\n",
        "    tqdm_batches.update(1)\n",
        "\n",
        "  tqdm_batches.close()\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/train_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(train_labels, f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/train_features.pkl', 'wb') as f:\n",
        "    pickle.dump(train_features, f)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV4DfBBNlOQW"
      },
      "outputs": [],
      "source": [
        "if load_features == False:\n",
        "  # Create an empty array to allocate all testset labels\n",
        "  # Create an empty array to allocate all testset features\n",
        "  test_labels = np.zeros((testset.__len__(), 1))\n",
        "  test_features = np.zeros((testset.__len__(), 1, features_shape[0], features_shape[1], features_shape[2]))\n",
        "\n",
        "  n = 0\n",
        "\n",
        "  tqdm_batches = tqdm_notebook(total= testset.__len__(), desc=f'Test set', unit='item')\n",
        "\n",
        "  for inp, mask, label in testloader:\n",
        "    inp = inp.to(device)\n",
        "    mask = mask.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Allocate label\n",
        "    test_labels[n] = label.cpu().numpy()\n",
        "\n",
        "    # Run the model with input image and extract features where hook is placed\n",
        "    with torch.no_grad():\n",
        "      outmask = model(inp)\n",
        "      test_features[n] = (model.hook.output).cpu().numpy()\n",
        "\n",
        "    n += 1\n",
        "    tqdm_batches.update(1)\n",
        "\n",
        "  tqdm_batches.close()\n",
        "\n",
        "  #----------------------------------------------------------------------------------------\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/test_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(test_labels, f)\n",
        "  f.close()\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/test_features.pkl', 'wb') as f:\n",
        "    pickle.dump(test_features, f)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxFZD3ISZ-t"
      },
      "source": [
        "# SVM for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshape features** \\\\\n",
        "Training and test features and labels must be reshaped to be fed to SVM to remove division in batches and to flatten them.\n",
        "* Features are reshaped to arrays of size = (len(dataset), len(flattened features array)).\n",
        "* Labels are reshaped to arrays of size = (len(dataset))\n",
        "\n"
      ],
      "metadata": {
        "id": "dVIspsG_BMAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHju-N-MUkSz"
      },
      "outputs": [],
      "source": [
        "train_features_flat = train_features.reshape((-1, features_shape[0] * features_shape[1] * features_shape[2]))\n",
        "train_labels_flat = train_labels.reshape((-1))\n",
        "\n",
        "test_features_flat = test_features.reshape((-1, features_shape[0] * features_shape[1] * features_shape[2]))\n",
        "test_labels_flat = test_labels.reshape((-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM for classification** \\\\\n",
        "The following cell computes a SVM for classification and is trained with the flattened train features and labels and saves it externally. \\\\\n",
        "When compute_svm = False, an already trained SVM is loaded."
      ],
      "metadata": {
        "id": "Nvxw0ErIB4MH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57AUgOI2mpa6"
      },
      "outputs": [],
      "source": [
        "compute_svm = False\n",
        "if compute_svm:\n",
        "  #Define SVM\n",
        "  svc = svm.SVC(kernel = 'linear')\n",
        "\n",
        "  #Train SVM\n",
        "  svc.fit(train_features_flat, train_labels_flat)\n",
        "\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/svc2006.pkl', 'wb') as f:\n",
        "    pickle.dump(svc, f)\n",
        "  f.close()\n",
        "\n",
        "else:\n",
        "  with open('/content/drive/MyDrive/ACT/Final project/Features/svc2006.pkl', 'rb') as f:\n",
        "    svc = pickle.load(f)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict labels** \\\\\n",
        "Labels are predicted using the test set."
      ],
      "metadata": {
        "id": "LHM7kH5SCWCB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPIoNumj32jh"
      },
      "outputs": [],
      "source": [
        "pred_labels = svc.predict(test_features_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute metrics** \\\\\n",
        "The following function computes the macro accuracy of the classification prediction by averaging the accuracy scores for each class.\n"
      ],
      "metadata": {
        "id": "JfN5SessCfW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_accuracy_score(gt, pred):\n",
        "  class0_test =  gt[np.argwhere(gt == 0)]\n",
        "  class0_pred = pred[np.argwhere(gt == 0)]\n",
        "\n",
        "  class1_test =  gt[np.argwhere(gt == 1)]\n",
        "  class1_pred = pred[np.argwhere(gt == 1)]\n",
        "\n",
        "  accuracy0 = accuracy_score(class0_test, class0_pred)\n",
        "  accuracy1 = accuracy_score(class1_test, class1_pred)\n",
        "\n",
        "  accuracy_tot = (accuracy0 + accuracy1) / 2\n",
        "\n",
        "  return accuracy_tot"
      ],
      "metadata": {
        "id": "nsEojglah6pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Micro and macro accuracy and the confusion matrix are computed for the test predictions."
      ],
      "metadata": {
        "id": "1IyfAa5nC0k-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRaWJxugO246"
      },
      "outputs": [],
      "source": [
        "micro_accuracy = accuracy_score(test_labels_flat, pred_labels)\n",
        "macro_accuracy = macro_accuracy_score(test_labels_flat, pred_labels)\n",
        "conf_matr = confusion_matrix(test_labels_flat, pred_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('SVC micro accuracy: %.4f' % micro_accuracy)\n",
        "print('SVC macro accuracy: %.4f' % macro_accuracy)"
      ],
      "metadata": {
        "id": "vaoYUL--i9Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxyrgorNQK64"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix = conf_matr,\n",
        "                              display_labels= svc.classes_)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rNkv7pOuzqxd",
        "SEHK5anZzoBr"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}